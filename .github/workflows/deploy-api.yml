name: Deploy API to Google Cloud Run

on:
  push:
    branches:
      - main
    paths:
      - 'api/**'
      - '.github/workflows/deploy-api.yml'
  workflow_dispatch:

env:
  PROJECT_ID: hantibink
  REGION: us-central1
  SERVICE_NAME: hantibink-api

jobs:
  deploy:
    name: Deploy API
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker for GCR
        run: gcloud auth configure-docker --quiet

      # Debug: Check AUTO_MIGRATE setting
      - name: Check AUTO_MIGRATE setting
        run: |
          echo "AUTO_MIGRATE is set to: '${{ vars.AUTO_MIGRATE }}'"
          if [ "${{ vars.AUTO_MIGRATE }}" = "true" ]; then
            echo "✅ Migrations will be applied automatically"
          else
            echo "⏭️ Skipping automatic migrations (AUTO_MIGRATE != 'true')"
          fi

      # Create database backup before migrations (production only)
      - name: Create database backup (if migrations enabled)
        if: ${{ vars.AUTO_MIGRATE == 'true' && github.ref == 'refs/heads/main' }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
        run: |
          echo "📦 Creating database backup before migration..."
          # Note: For Supabase, you can use their dashboard or API
          # This is a placeholder - replace with your backup method
          # Example: pg_dump $DATABASE_URL > backup_$(date +%Y%m%d_%H%M%S).sql
          echo "⚠️  Backup reminder: Consider using Supabase dashboard for production backups"
          echo "Timestamp: $(date -u +%Y-%m-%d_%H:%M:%S_UTC)"

      # Apply migrations BEFORE building the Docker image
      - name: Apply migrations (if AUTO_MIGRATE enabled)
        if: ${{ vars.AUTO_MIGRATE == 'true' }}
        working-directory: ./api
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
          DIRECT_URL: ${{ secrets.SUPABASE_DIRECT_URL }}
          NODE_OPTIONS: "--dns-result-order=ipv4first"
          MIGRATION_LOCK_KEY: "migration_lock_${{ github.sha }}"
        run: |
          echo "🔄 Applying migrations before build..."
          
          # Force IPv4 DNS resolution system-wide (more aggressive approach)
          echo "🔧 Configuring IPv4-only DNS resolution..."
          sudo sed -i 's/#precedence ::ffff:0:0\/96  100/precedence ::ffff:0:0\/96  100/' /etc/gai.conf || true
          sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1 || true
          sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1 || true
          
          # Install dependencies first
          npm ci
          npx prisma generate
          
          # Simple lock mechanism using database (after dependencies are installed)
          echo "🔒 Acquiring migration lock..."
          node -e "
            const { PrismaClient } = require('@prisma/client');
            const prisma = new PrismaClient();
            const lockKey = process.env.MIGRATION_LOCK_KEY;
            
            async function acquireLock() {
              try {
                // Try to create a lock record (you'd need a Lock table for this)
                // For now, just log the attempt
                console.log('Lock key:', lockKey);
                console.log('✅ Lock acquired (or proceeding without lock)');
                await prisma.\$disconnect();
              } catch (err) {
                console.error('⚠️  Could not acquire lock, proceeding anyway:', err.message);
                await prisma.\$disconnect();
              }
            }
            acquireLock();
          " || true
          
          # Retry logic for Supabase connection issues
          MAX_RETRIES=3
          RETRY_DELAY=30
          SUCCESS=false
          
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Migration attempt $i of $MAX_RETRIES..."
            
            # Use timeout to prevent hanging connections
            if timeout 60 npx prisma migrate deploy; then
              echo "✅ Migrations applied successfully on attempt $i"
              SUCCESS=true
              break
            else
              echo "❌ Migration failed on attempt $i"
              if [ $i -lt $MAX_RETRIES ]; then
                echo "Retrying in ${RETRY_DELAY} seconds..."
                sleep $RETRY_DELAY
              fi
            fi
          done
          
          if [ "$SUCCESS" = false ]; then
            echo "❌ Migrations failed after $MAX_RETRIES attempts"
            
            # Send failure notification (placeholder for Slack/Discord)
            echo "📢 MIGRATION FAILURE NOTIFICATION"
            echo "Environment: Production"
            echo "Branch: ${{ github.ref_name }}"
            echo "Commit: ${{ github.sha }}"
            echo "Time: $(date -u +%Y-%m-%d_%H:%M:%S_UTC)"
            
            # Example: Send to Slack (requires SLACK_WEBHOOK secret)
            # if [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
            #   curl -X POST -H 'Content-type: application/json' \
            #     --data "{\"text\":\"🚨 Migration failed in production after $MAX_RETRIES attempts\"}" \
            #     ${{ secrets.SLACK_WEBHOOK }} || true
            # fi
            
            exit 1
          fi
          
          echo "📢 Migration succeeded - consider sending success notification"

      - name: Build Docker image
        working-directory: ./api
        run: |
          # Create optimized Dockerfile
          cat > Dockerfile.ci << 'EOF'
          FROM node:18-slim
          
          RUN apt-get update -y && apt-get install -y openssl && rm -rf /var/lib/apt/lists/*
          
          WORKDIR /app
          
          # Copy package.json and prisma schema
          COPY package.json ./
          COPY prisma ./prisma/
          
          # Install production dependencies
          RUN npm install --omit=dev
          
          # Generate Prisma client with current schema
          RUN npx prisma generate
          
          # Copy the rest of the application
          COPY . .
          
          EXPOSE 8080
          
          CMD ["npm", "start"]
          EOF
          
          # CRITICAL: --no-cache forces fresh Prisma client generation
          # Without this, the API may use an outdated Prisma client that doesn't match the database schema
          docker build --platform linux/amd64 --no-cache -f Dockerfile.ci -t gcr.io/$PROJECT_ID/$SERVICE_NAME:$GITHUB_SHA .
          docker tag gcr.io/$PROJECT_ID/$SERVICE_NAME:$GITHUB_SHA gcr.io/$PROJECT_ID/$SERVICE_NAME:latest

      - name: Push Docker image to GCR
        run: |
          docker push gcr.io/$PROJECT_ID/$SERVICE_NAME:$GITHUB_SHA
          docker push gcr.io/$PROJECT_ID/$SERVICE_NAME:latest

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy $SERVICE_NAME \
            --image gcr.io/$PROJECT_ID/$SERVICE_NAME:$GITHUB_SHA \
            --platform managed \
            --region $REGION \
            --allow-unauthenticated \
            --set-env-vars="NODE_ENV=production,HOST=0.0.0.0,FIREBASE_PROJECT_ID=hantibink,DATABASE_URL=${{ secrets.SUPABASE_DATABASE_URL }},DIRECT_URL=${{ secrets.SUPABASE_DIRECT_URL }},JWT_SECRET=${{ secrets.JWT_SECRET }}" \
            --min-instances=0 \
            --max-instances=10 \
            --memory=512Mi

      - name: Get Service URL
        run: |
          SERVICE_URL=$(gcloud run services describe $SERVICE_NAME --region=$REGION --format='value(status.url)')
          echo "API deployed to: $SERVICE_URL"
          echo "SERVICE_URL=$SERVICE_URL" >> $GITHUB_ENV

      - name: Test deployment
        run: |
          curl -f ${{ env.SERVICE_URL }}/health || exit 1
          echo "Health check passed!"

